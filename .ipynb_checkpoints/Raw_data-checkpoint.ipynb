{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Raw DNA strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we train SVM on string data (DNA strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kernel import *\n",
    "\n",
    "from KernelSVM import KernelSVM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from processing import train_test_split, load_y\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DNA string : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GAAAAAACGTTAGCAAACAAGGAACAAAGACAAAGCTGTCAACGGTCCATGGAATCTTGAAATTTAAATAATTGTTACACATTTTGTTTTGTTCTAACTGT'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "dataset_index = '2'\n",
    "\n",
    "# load DNA strings \n",
    "f = open('data/train/Xtr{}.csv'.format(dataset_index), 'r')\n",
    "data += [line.strip('\\n') for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "# load target vector \n",
    "y = (load_y(\"data/train/Ytr{}.csv\".format(dataset_index)))\n",
    "y = 2*y - 1 # transform y to lie in {-1, 1} instead of {0, 1}\n",
    "y = np.reshape(y.astype(float), -1) # \n",
    "\n",
    "print('First DNA string : ')\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data[:1500], y[:1500], data[1500:], y[1500:]\n",
    "#X_train, y_train, X_test, y_test = X_train[:75], y_train[:75], X_test[:25], y_test[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set lifted\n",
      "Test set lifted\n",
      "Gamma : 0.5, Lambda : 0.0001, Score: 63.0\n",
      "Gamma : 0.5, Lambda : 0.0006210526315789474, Score: 63.6\n",
      "Gamma : 0.5, Lambda : 0.0011421052631578948, Score: 66.0\n",
      "Gamma : 0.5, Lambda : 0.0016631578947368423, Score: 67.2\n",
      "Gamma : 0.5, Lambda : 0.0021842105263157894, Score: 67.0\n",
      "Gamma : 0.5, Lambda : 0.0027052631578947366, Score: 67.0\n",
      "Gamma : 0.5, Lambda : 0.0032263157894736843, Score: 67.0\n",
      "Gamma : 0.5, Lambda : 0.0037473684210526316, Score: 67.0\n",
      "Gamma : 0.5, Lambda : 0.004268421052631579, Score: 67.0\n",
      "Gamma : 0.5, Lambda : 0.004789473684210527, Score: 67.2\n",
      "Gamma : 0.5, Lambda : 0.005310526315789474, Score: 67.80000000000001\n",
      "Gamma : 0.5, Lambda : 0.005831578947368421, Score: 68.2\n",
      "Gamma : 0.5, Lambda : 0.006352631578947369, Score: 68.2\n",
      "Gamma : 0.5, Lambda : 0.0068736842105263166, Score: 68.4\n",
      "Gamma : 0.5, Lambda : 0.007394736842105264, Score: 68.60000000000001\n",
      "Gamma : 0.5, Lambda : 0.00791578947368421, Score: 68.8\n",
      "Gamma : 0.5, Lambda : 0.008436842105263158, Score: 68.60000000000001\n",
      "Gamma : 0.5, Lambda : 0.008957894736842106, Score: 68.8\n",
      "Gamma : 0.5, Lambda : 0.009478947368421052, Score: 68.60000000000001\n",
      "Gamma : 0.5, Lambda : 0.01, Score: 68.8\n",
      "Train set lifted\n",
      "Test set lifted\n",
      "Gamma : 0.6, Lambda : 0.0001, Score: 65.60000000000001\n",
      "Gamma : 0.6, Lambda : 0.0006210526315789474, Score: 65.4\n",
      "Gamma : 0.6, Lambda : 0.0011421052631578948, Score: 65.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-13b96826c84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m#clf_sk.fit(X_lift_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lift_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m#y_pred_test_sk = clf_sk.predict(X_lift_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/Google Drive/Cours/MVA/S2/Machine Learning with Kernel Methods/KernelDNA/KernelSVM.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Predicting on a BinarySVC for data X_test of shape {} ...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Stats about the predictions: (0 should never be predicted, labels are in {-1,+1})\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/Google Drive/Cours/MVA/S2/Machine Learning with Kernel Methods/KernelDNA/KernelSVM.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             y_predict[i] = sum(alpha * self.kernel(X_test[i], sv,**self.kernel_parameters)\n\u001b[0;32m--> 131\u001b[0;31m                                for alpha, sv in zip(self.alpha, self.sv))\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m#return y_predict + self.b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/Google Drive/Cours/MVA/S2/Machine Learning with Kernel Methods/KernelDNA/KernelSVM.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             y_predict[i] = sum(alpha * self.kernel(X_test[i], sv,**self.kernel_parameters)\n\u001b[0;32m--> 131\u001b[0;31m                                for alpha, sv in zip(self.alpha, self.sv))\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m#return y_predict + self.b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/Google Drive/Cours/MVA/S2/Machine Learning with Kernel Methods/KernelDNA/kernel.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\" Linear kernel : dot product K(X, Y) = (X^T) Y\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Compute matrices and vectors for a given kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### TEST of the KITCHENS SINKs\n",
    "alpha_size = 4\n",
    "\n",
    "M = 6*2048\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "kernel_parameters = {} # no parameters for linear kernel\n",
    "\n",
    "\"\"\" \n",
    "X_lift_train = phi_sink(X_train, k, gamma, M)\n",
    "print(\"Train set lifted\")\n",
    "X_lift_test = phi_sink(X_test, k, gamma, M)\n",
    "print(\"Test set lifted\")\n",
    "\"\"\"\n",
    "for k in [7, 8, 9]:\n",
    "    for gamma in np.linspace(0.5, 1.2, 8):\n",
    "        W = gamma*np.random.randn(M,4*k)\n",
    "        b = (2*np.pi)*np.random.rand(M)\n",
    "\n",
    "        X_train_ = sequence_to_matrix(X_train)\n",
    "        X_test_ = sequence_to_matrix(X_test)\n",
    "\n",
    "        X_lift_train = compute_conv_features(X_train_, W, b, alpha_size = alpha_size)\n",
    "        print(\"Train set lifted\")\n",
    "        X_lift_test = compute_conv_features(X_test_, W, b, alpha_size = alpha_size)\n",
    "        print(\"Test set lifted\")\n",
    "\n",
    "        clf = KernelSVM(lambda_reg = 0, loss=\"squared_hinge\", kernel = linear, \n",
    "                    kernel_parameters = kernel_parameters, data_type='vector', threshold=0, verbose=False)\n",
    "                \n",
    "        for lambda_reg in np.linspace(0.0001, 0.01, 20):\n",
    "\n",
    "            clf_sk = LinearSVC(C=1/(2*1500*lambda_reg))\n",
    "            \n",
    "            clf.lambda_reg = lambda_reg\n",
    "\n",
    "            clf.fit(X_lift_train, y_train)\n",
    "            \n",
    "            #clf_sk.fit(X_lift_train, y_train)\n",
    "\n",
    "            y_pred_test = clf.predict(X_lift_test)\n",
    "            #y_pred_test_sk = clf_sk.predict(X_lift_test)\n",
    "            \n",
    "            score =  sum(y_test == y_pred_test)/len(y_test)*100\n",
    "            #score_sk =  sum(y_test == y_pred_test_sk)/len(y_test)*100\n",
    "            \n",
    "            print('Gamma : {}, Lambda : {}, Score: {}'.format(gamma, lambda_reg, score))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gamma = gamma\n",
    "                best_lambda = lambda_reg\n",
    "                best_k = k\n",
    "                best_W = W\n",
    "                best_b = b\n",
    "\n",
    "print('Best k : {}, best gamma : {}, best lambda : {}, best score: {}'.format(best_k, best_gamma, best_lambda, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('W_0.npy', best_W)\n",
    "#np.save('b_0.npy', best_b)\n",
    "\n",
    "\n",
    "# k = 7, M =10\n",
    "#Gamma : 1.0, Lambda : 0.06210526315789474, Score: 70.19999999999999\n",
    "#Gamma : 1.0, Lambda : 0.11421052631578947, Score: 70.8\n",
    "#Gamma : 1.0, Lambda : 0.16631578947368422, Score: 71.2\n",
    "#Gamma : 1.0, Lambda : 0.21842105263157896, Score: 71.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_W = np.load(\"W_2.npy\") \n",
    "best_b = np.load(\"b_2.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building kernel matrix:   0%|          | 0/1500 [00:00<?, ?it/s]\u001b[A\n",
      "Building kernel matrix:   5%|▍         | 74/1500 [00:00<00:02, 652.37it/s]\u001b[A\n",
      "Building kernel matrix:   7%|▋         | 98/1500 [00:00<00:02, 471.92it/s]\u001b[A\n",
      "Building kernel matrix:   8%|▊         | 127/1500 [00:00<00:03, 417.50it/s]\u001b[A\n",
      "Building kernel matrix:  10%|█         | 156/1500 [00:00<00:03, 385.52it/s]\u001b[A\n",
      "Building kernel matrix:  12%|█▏        | 182/1500 [00:00<00:03, 330.16it/s]\u001b[A\n",
      "Building kernel matrix:  14%|█▎        | 206/1500 [00:00<00:04, 271.63it/s]\u001b[A\n",
      "Building kernel matrix:  15%|█▌        | 226/1500 [00:00<00:05, 243.44it/s]\u001b[A\n",
      "Building kernel matrix:  16%|█▋        | 244/1500 [00:01<00:05, 230.73it/s]\u001b[A\n",
      "Building kernel matrix:  17%|█▋        | 261/1500 [00:01<00:05, 222.52it/s]\u001b[A\n",
      "Building kernel matrix:  18%|█▊        | 277/1500 [00:01<00:06, 199.98it/s]\u001b[A\n",
      "Building kernel matrix:  19%|█▉        | 291/1500 [00:01<00:06, 195.29it/s]\u001b[A\n",
      "Building kernel matrix:  20%|██        | 305/1500 [00:01<00:06, 190.87it/s]\u001b[A\n",
      "Building kernel matrix:  21%|██▏       | 319/1500 [00:01<00:06, 183.72it/s]\u001b[A\n",
      "Building kernel matrix:  22%|██▏       | 332/1500 [00:01<00:06, 178.11it/s]\u001b[A\n",
      "Building kernel matrix:  23%|██▎       | 344/1500 [00:01<00:06, 172.71it/s]\u001b[A\n",
      "Building kernel matrix:  24%|██▎       | 355/1500 [00:02<00:07, 158.70it/s]\u001b[A\n",
      "Building kernel matrix:  24%|██▍       | 365/1500 [00:02<00:07, 153.25it/s]\u001b[A\n",
      "Building kernel matrix:  25%|██▌       | 376/1500 [00:02<00:07, 151.19it/s]\u001b[A\n",
      "Building kernel matrix:  26%|██▌       | 385/1500 [00:02<00:07, 144.84it/s]\u001b[A\n",
      "Building kernel matrix:  26%|██▋       | 395/1500 [00:02<00:07, 143.21it/s]\u001b[A\n",
      "Building kernel matrix:  27%|██▋       | 405/1500 [00:02<00:07, 141.03it/s]\u001b[A\n",
      "Building kernel matrix:  28%|██▊       | 414/1500 [00:02<00:07, 138.23it/s]\u001b[A\n",
      "Building kernel matrix:  28%|██▊       | 423/1500 [00:03<00:07, 135.76it/s]\u001b[A\n",
      "Building kernel matrix:  29%|██▉       | 433/1500 [00:03<00:07, 134.31it/s]\u001b[A\n",
      "Building kernel matrix:  30%|██▉       | 443/1500 [00:03<00:07, 133.17it/s]\u001b[A\n",
      "Building kernel matrix:  30%|███       | 452/1500 [00:03<00:07, 131.29it/s]\u001b[A\n",
      "Building kernel matrix:  31%|███       | 462/1500 [00:03<00:07, 129.99it/s]\u001b[A\n",
      "Building kernel matrix:  31%|███▏      | 471/1500 [00:03<00:07, 128.77it/s]\u001b[A\n",
      "Building kernel matrix:  32%|███▏      | 480/1500 [00:03<00:07, 127.73it/s]\u001b[A\n",
      "Building kernel matrix:  33%|███▎      | 489/1500 [00:03<00:08, 126.21it/s]\u001b[A\n",
      "Building kernel matrix:  33%|███▎      | 498/1500 [00:03<00:08, 125.09it/s]\u001b[A\n",
      "Building kernel matrix:  34%|███▍      | 507/1500 [00:04<00:08, 123.98it/s]\u001b[A\n",
      "Building kernel matrix:  34%|███▍      | 516/1500 [00:04<00:08, 122.91it/s]\u001b[A\n",
      "Building kernel matrix:  35%|███▌      | 525/1500 [00:04<00:07, 121.95it/s]\u001b[A\n",
      "Building kernel matrix:  36%|███▌      | 534/1500 [00:04<00:07, 120.88it/s]\u001b[A\n",
      "Building kernel matrix:  36%|███▌      | 543/1500 [00:04<00:07, 119.77it/s]\u001b[A\n",
      "Building kernel matrix:  37%|███▋      | 552/1500 [00:04<00:07, 118.91it/s]\u001b[A\n",
      "Building kernel matrix:  37%|███▋      | 561/1500 [00:04<00:07, 118.21it/s]\u001b[A\n",
      "Building kernel matrix:  38%|███▊      | 570/1500 [00:04<00:07, 117.37it/s]\u001b[A\n",
      "Building kernel matrix:  39%|███▊      | 579/1500 [00:04<00:07, 116.66it/s]\u001b[A\n",
      "Building kernel matrix:  39%|███▉      | 588/1500 [00:05<00:07, 115.82it/s]\u001b[A\n",
      "Building kernel matrix:  40%|███▉      | 597/1500 [00:05<00:07, 115.12it/s]\u001b[A\n",
      "Building kernel matrix:  40%|████      | 606/1500 [00:05<00:07, 114.48it/s]\u001b[A\n",
      "Building kernel matrix:  41%|████      | 615/1500 [00:05<00:07, 113.82it/s]\u001b[A\n",
      "Building kernel matrix:  42%|████▏     | 624/1500 [00:05<00:07, 113.06it/s]\u001b[A\n",
      "Building kernel matrix:  42%|████▏     | 633/1500 [00:05<00:07, 112.24it/s]\u001b[A\n",
      "Building kernel matrix:  43%|████▎     | 641/1500 [00:05<00:07, 111.34it/s]\u001b[A\n",
      "Building kernel matrix:  43%|████▎     | 649/1500 [00:05<00:07, 109.87it/s]\u001b[A\n",
      "Building kernel matrix:  44%|████▎     | 656/1500 [00:06<00:07, 109.02it/s]\u001b[A\n",
      "Building kernel matrix:  44%|████▍     | 663/1500 [00:06<00:07, 106.00it/s]\u001b[A\n",
      "Building kernel matrix:  45%|████▍     | 669/1500 [00:06<00:08, 102.28it/s]\u001b[A\n",
      "Building kernel matrix:  45%|████▍     | 674/1500 [00:06<00:08, 100.72it/s]\u001b[A\n",
      "Building kernel matrix:  45%|████▌     | 679/1500 [00:06<00:08, 99.55it/s] \u001b[A\n",
      "Building kernel matrix:  46%|████▌     | 684/1500 [00:06<00:08, 98.62it/s]\u001b[A\n",
      "Building kernel matrix:  46%|████▌     | 690/1500 [00:07<00:08, 97.86it/s]\u001b[A\n",
      "Building kernel matrix:  46%|████▋     | 696/1500 [00:07<00:08, 97.17it/s]\u001b[A\n",
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Schreuder/anaconda/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/Schreuder/anaconda/lib/python3.5/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/Schreuder/anaconda/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "Building kernel matrix: 100%|██████████| 1500/1500 [00:28<00:00, 51.86it/s]\n",
      "Predicting values:   0%|          | 1/500 [00:00<01:08,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 500/500 [01:01<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 6} 0.01 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values:   0%|          | 1/500 [00:00<01:14,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 500/500 [00:55<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 6} 0.12 0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values:   0%|          | 1/500 [00:00<00:58,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 500/500 [00:56<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 6} 0.23 0.746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4e782f632aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# train svm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/Google Drive/Cours/MVA/S2/Machine Learning with Kernel Methods/KernelDNA/KernelSVM.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Find solution using cvxopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/anaconda/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4468\u001b[0m             'residual as dual infeasibility certificate': dinfres} \n\u001b[1;32m   4469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4470\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Schreuder/anaconda/lib/python3.5/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m         \u001b[0;31m# Update lambda and scaling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m         \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Schreuder/anaconda/lib/python3.5/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mupdate_scaling\u001b[0;34m(W, lmbda, s, z)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# d := d .* s .* z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Grid search for parameters\n",
    "\n",
    "kernel_parameters_list = [{'k':6}, {'k':7}, {'k':8}]\n",
    "best_score = 0\n",
    "best_param = None\n",
    "\n",
    "for kernel_parameters in kernel_parameters_list:\n",
    "    \n",
    "    svm = KernelSVM(lambda_reg = 1, loss='hinge', kernel = spectrum_kernel, \n",
    "                kernel_parameters = kernel_parameters, data_type='string')\n",
    "\n",
    "    for lambda_reg in np.linspace(0.01,1, 10):\n",
    "        \n",
    "        svm.lambda_reg = lambda_reg\n",
    "        \n",
    "        # train svm\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = svm.pred(X_test)\n",
    "\n",
    "        #print('Score : ')\n",
    "        #sum(y_test == y_pred)/len(y_test)\n",
    "        score = sum(y_test == y_pred)/len(y_test)\n",
    "        print(kernel_parameters, lambda_reg, score)\n",
    "        if score > best_score:\n",
    "            best_score=score\n",
    "            best_param = lambda_reg, kernel_parameters\n",
    "            \n",
    "print(best_score)\n",
    "print(best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.zeros((3000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building kernel matrix: 100%|██████████| 2000/2000 [01:01<00:00, 32.68it/s]\n",
      "Predicting values:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 1000/1000 [02:41<00:00,  6.20it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_index = 0\n",
    "\n",
    "# load DNA strings \n",
    "data = []\n",
    "f = open('data/train/Xtr{}.csv'.format(dataset_index), 'r')\n",
    "data += [line.strip('\\n') for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "# load target vector \n",
    "y = (load_y(\"data/train/Ytr{}.csv\".format(dataset_index)))\n",
    "y = 2*y - 1 # transform y to lie in {-1, 1} instead of {0, 1}\n",
    "y = np.reshape(y.astype(float), -1) # \n",
    "\n",
    "X_train, y_train = data, y\n",
    "\n",
    "kernel_parameters = {'k':6}\n",
    "\n",
    "clf =  KernelSVM(lambda_reg = 0.1, loss='hinge', kernel = spectrum_kernel, \n",
    "                kernel_parameters = kernel_parameters, data_type='string')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "f_ = open('data/test/Xte{}.csv'.format(dataset_index), 'r')\n",
    "X_test = [line.strip('\\n') for line in f_.readlines()]\n",
    "f_.close()\n",
    "\n",
    "y_pred[1000*dataset_index:1000*(dataset_index+1)] = np.reshape(clf.pred(X_test), (1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_index = 1\n",
    "\n",
    "alpha_size = 4\n",
    "\n",
    "kernel_parameters = {}\n",
    "\n",
    "# load DNA strings \n",
    "data = []\n",
    "f = open('data/train/Xtr{}.csv'.format(dataset_index), 'r')\n",
    "data += [line.strip('\\n') for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "# load target vector \n",
    "y = (load_y(\"data/train/Ytr{}.csv\".format(dataset_index)))\n",
    "y = 2*y - 1 # transform y to lie in {-1, 1} instead of {0, 1}\n",
    "y = np.reshape(y.astype(float), -1) # \n",
    "\n",
    "X_train, y_train = data, y\n",
    "\n",
    "W = np.load('W_1.npy')\n",
    "b = np.load('b_1.npy')\n",
    "\n",
    "X_train_ = sequence_to_matrix(X_train)\n",
    "\n",
    "X_lift_train = compute_conv_features(X_train_, W, b, alpha_size = alpha_size)\n",
    "\n",
    "clf = KernelSVM(lambda_reg = 0.054210526315789466, loss=\"squared_hinge\", kernel = linear, \n",
    "            kernel_parameters = kernel_parameters, data_type='vector', threshold=0, verbose=False)\n",
    "\n",
    "clf.fit(X_lift_train, y_train)\n",
    "\n",
    "f_ = open('data/test/Xte{}.csv'.format(dataset_index), 'r')\n",
    "X_test = [line.strip('\\n') for line in f_.readlines()]\n",
    "f_.close()\n",
    "\n",
    "X_test_ = sequence_to_matrix(X_test)\n",
    "\n",
    "X_lift_test = compute_conv_features(X_test_, W, b, alpha_size = alpha_size)\n",
    "\n",
    "y_pred[1000*dataset_index:1000*(dataset_index+1)] = np.reshape(clf.predict(X_lift_test), (1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_index = 2\n",
    "\n",
    "alpha_size = 4\n",
    "\n",
    "# load DNA strings \n",
    "data = []\n",
    "f = open('data/train/Xtr{}.csv'.format(dataset_index), 'r')\n",
    "data += [line.strip('\\n') for line in f.readlines()]\n",
    "f.close()\n",
    "\n",
    "# load target vector \n",
    "y = (load_y(\"data/train/Ytr{}.csv\".format(dataset_index)))\n",
    "y = 2*y - 1 # transform y to lie in {-1, 1} instead of {0, 1}\n",
    "y = np.reshape(y.astype(float), -1) # \n",
    "\n",
    "X_train, y_train = data, y\n",
    "\n",
    "W = np.load('W_2.npy')\n",
    "b = np.load('b_2.npy')\n",
    "\n",
    "X_train_ = sequence_to_matrix(X_train)\n",
    "\n",
    "X_lift_train = compute_conv_features(X_train_, W, b, alpha_size = alpha_size)\n",
    "\n",
    "clf = KernelSVM(lambda_reg = 0.16631578947368422, loss=\"squared_hinge\", kernel = linear, \n",
    "            kernel_parameters = kernel_parameters, data_type='vector', threshold=0, verbose=False)\n",
    "\n",
    "clf.fit(X_lift_train, y_train)\n",
    "\n",
    "f_ = open('data/test/Xte{}.csv'.format(dataset_index), 'r')\n",
    "X_test = [line.strip('\\n') for line in f_.readlines()]\n",
    "f_.close()\n",
    "\n",
    "X_test_ = sequence_to_matrix(X_test)\n",
    "\n",
    "X_lift_test = compute_conv_features(X_test_, W, b, alpha_size = alpha_size)\n",
    "\n",
    "y_pred[1000*dataset_index:1000*(dataset_index+1)] = np.reshape(clf.predict(X_lift_test), (1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_pred+1)/2 # to have y in 0 and 1\n",
    "df = pd.DataFrame(y_pred, columns=['Bound'])\n",
    "df.index.name = 'Id'\n",
    "df.Bound = df.Bound.astype(int)\n",
    "df.to_csv('mixed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((3000,))\n",
    "\n",
    "# kitchen sink\n",
    "alpha_size = 4\n",
    "M = 4*2048\n",
    "\n",
    "kernel_parameters = {}\n",
    "\n",
    "lambda_opt = [0.0441400304414003, 0.052631578947368425, 0.06210526315789474]\n",
    "gamma_opt = [0.9842105263157894, 0.9666666666666667, 0.831578947368421]\n",
    "k_opt = [8, 8, 7]\n",
    "\n",
    "for dataset_index in range(3):\n",
    "    print(dataset_index)\n",
    "    # load DNA strings \n",
    "    data = []\n",
    "    f = open('data/train/Xtr{}.csv'.format(dataset_index), 'r')\n",
    "    data += [line.strip('\\n') for line in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "    # load target vector \n",
    "    y = (load_y(\"data/train/Ytr{}.csv\".format(dataset_index)))\n",
    "    y = 2*y - 1 # transform y to lie in {-1, 1} instead of {0, 1}\n",
    "    y = np.reshape(y.astype(float), -1) # \n",
    "\n",
    "    X_train, y_train = data, y\n",
    "    \n",
    "    W = gamma_opt[dataset_index]*np.random.randn(M,4*k_opt[dataset_index])\n",
    "    b = (2*np.pi)*np.random.rand(M)\n",
    "\n",
    "    X_train_ = sequence_to_matrix(X_train)\n",
    "\n",
    "    X_lift_train = compute_conv_features(X_train_, W, b, alpha_size = alpha_size)\n",
    "\n",
    "    clf = KernelSVM(lambda_reg = lambda_opt[dataset_index], loss=\"squared_hinge\", kernel = linear, \n",
    "                kernel_parameters = kernel_parameters, data_type='vector', threshold=0, verbose=False)\n",
    "\n",
    "    clf.fit(X_lift_train, y_train)\n",
    "        \n",
    "    f_ = open('data/test/Xte{}.csv'.format(dataset_index), 'r')\n",
    "    X_test = [line.strip('\\n') for line in f_.readlines()]\n",
    "    f_.close()\n",
    "    \n",
    "    X_test_ = sequence_to_matrix(X_test)\n",
    "    \n",
    "    X_lift_test = compute_conv_features(X_test_, W, b, alpha_size = alpha_size)\n",
    "    \n",
    "    y_pred[1000*dataset_index:1000*(dataset_index+1)] = np.reshape(clf.predict(X_lift_test), (1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (y_pred+1)/2 # to have y in 0 and 1\n",
    "df = pd.DataFrame(y_pred, columns=['Bound'])\n",
    "df.index.name = 'Id'\n",
    "df.Bound = df.Bound.astype(int)\n",
    "df.to_csv('submit_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building kernel matrix: 100%|██████████| 2000/2000 [00:31<00:00, 62.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.0459e+01 -4.5490e+01  5e+03  7e+01  1e-14\n",
      " 1: -4.5703e+01 -3.4125e+01  6e+02  8e+00  1e-14\n",
      " 2: -2.2657e+01 -1.6444e+01  2e+02  2e+00  6e-15\n",
      " 3: -9.5445e+00 -1.1559e+01  3e+01  3e-01  2e-15\n",
      " 4: -5.7943e+00 -9.2809e+00  4e+00  4e-03  9e-16\n",
      " 5: -6.1193e+00 -6.7273e+00  6e-01  6e-04  6e-16\n",
      " 6: -6.2542e+00 -6.3671e+00  1e-01  5e-05  6e-16\n",
      " 7: -6.2928e+00 -6.3026e+00  1e-02  3e-06  6e-16\n",
      " 8: -6.2967e+00 -6.2971e+00  3e-04  8e-08  7e-16\n",
      " 9: -6.2969e+00 -6.2969e+00  1e-05  2e-09  6e-16\n",
      "10: -6.2969e+00 -6.2969e+00  3e-07  2e-11  7e-16\n",
      "Optimal solution found.\n",
      "[   0    1    2 ... 1996 1997 1999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values:   0%|          | 1/1000 [00:00<01:48,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 1000/1000 [01:51<00:00,  9.01it/s]\n",
      "Building kernel matrix: 100%|██████████| 2000/2000 [00:30<00:00, 65.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8829e+01 -4.0671e+01  5e+03  7e+01  6e-15\n",
      " 1: -2.7091e+01 -3.5225e+01  5e+02  6e+00  6e-15\n",
      " 2: -1.5188e+01 -2.6530e+01  1e+02  1e+00  4e-15\n",
      " 3: -9.3484e+00 -2.4162e+01  4e+01  3e-01  2e-15\n",
      " 4: -8.1452e+00 -1.5392e+01  9e+00  2e-02  1e-15\n",
      " 5: -8.7394e+00 -9.9694e+00  1e+00  4e-03  1e-15\n",
      " 6: -9.0512e+00 -9.2459e+00  2e-01  4e-04  1e-15\n",
      " 7: -9.1109e+00 -9.1304e+00  2e-02  3e-05  1e-15\n",
      " 8: -9.1175e+00 -9.1191e+00  2e-03  1e-06  1e-15\n",
      " 9: -9.1181e+00 -9.1181e+00  6e-05  3e-08  1e-15\n",
      "10: -9.1181e+00 -9.1181e+00  2e-06  4e-10  1e-15\n",
      "Optimal solution found.\n",
      "[   0    2    5 ... 1997 1998 1999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values:   0%|          | 1/1000 [00:00<01:44,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 1000/1000 [01:48<00:00,  9.22it/s]\n",
      "Building kernel matrix: 100%|██████████| 2000/2000 [00:40<00:00, 49.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.9430e+03 -3.5752e+01  4e+04  2e+02  2e-12\n",
      " 1: -1.0559e+02 -3.3006e+01  1e+03  6e+00  2e-12\n",
      " 2: -1.2367e+01 -2.9323e+01  6e+01  2e-01  1e-13\n",
      " 3: -9.4820e+00 -1.7739e+01  8e+00  4e-17  8e-15\n",
      " 4: -1.0591e+01 -1.2302e+01  2e+00  3e-17  7e-15\n",
      " 5: -1.1076e+01 -1.1465e+01  4e-01  3e-17  7e-15\n",
      " 6: -1.1192e+01 -1.1290e+01  1e-01  3e-17  7e-15\n",
      " 7: -1.1225e+01 -1.1245e+01  2e-02  3e-17  8e-15\n",
      " 8: -1.1232e+01 -1.1235e+01  3e-03  3e-17  8e-15\n",
      " 9: -1.1234e+01 -1.1234e+01  1e-04  3e-17  8e-15\n",
      "10: -1.1234e+01 -1.1234e+01  2e-06  3e-17  8e-15\n",
      "Optimal solution found.\n",
      "[   0    1    2 ... 1996 1998 1999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values:   0%|          | 1/1000 [00:00<01:50,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of support vectors : 1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting values: 100%|██████████| 1000/1000 [01:51<00:00,  8.97it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros((3000,))\n",
    "\n",
    "# k-spectrum\n",
    "#lambda_opt=[0.12,0.035,0.066]\n",
    "#kernel_parameters_opt=[{'k':6}, {'k':6}, {'k':4}]\n",
    "\n",
    "\n",
    "for dataset_index in range(3):\n",
    "    # load DNA strings \n",
    "    data = []\n",
    "    f = open('data/train/Xtr{}.csv'.format(dataset_index), 'r')\n",
    "    data += [line.strip('\\n') for line in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "    # load target vector \n",
    "    y = (load_y(\"data/train/Ytr{}.csv\".format(dataset_index)))\n",
    "    y = 2*y - 1 # transform y to lie in {-1, 1} instead of {0, 1}\n",
    "    y = np.reshape(y.astype(float), -1) # \n",
    "\n",
    "    X_train, y_train, X_test, y_test = data, y, data[1500:], y[1500:]\n",
    "    \n",
    "    lambda_reg=lambda_opt[dataset_index]\n",
    "    kernel_parameters=kernel_parameters_opt[dataset_index]\n",
    "\n",
    "    SVM = KernelSVM(lambda_reg = lambda_reg, kernel = spectrum_kernel, \n",
    "                    kernel_parameters = kernel_parameters, data_type='string')\n",
    "    \n",
    "    SVM.fit(X_train, y_train)\n",
    "    #y_loc = SVM.pred(X_test)\n",
    "    #print(sum(y_test == y_loc)/len(y_test))\n",
    "    \n",
    "    #SVM.load('SVM_opt{}.npy'.format(i), 'Xtrain_{}.npy'.format(i) )\n",
    "    \n",
    "    \n",
    "    f_ = open('data/test/Xte{}.csv'.format(dataset_index), 'r')\n",
    "    X = [line.strip('\\n') for line in f_.readlines()]\n",
    "    f_.close()\n",
    "\n",
    "    y_pred[1000*dataset_index:1000*(dataset_index+1)] = np.reshape(SVM.pred(X), (1000,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
